Title: GitHub - tensorchord/pg_bestmatch.rs: Generate BM25 sparse vector inside PostgreSQL

URL Source: http://github.com/tensorchord/pg_bestmatch.rs

Markdown Content:
pg\_bestmatch.rs
----------------

[](http://github.com/tensorchord/pg_bestmatch.rs#pg_bestmatchrs)

This PostgreSQL extension provides functionalities for BM25 text queries, generateing BM25 statistic sparse vectors for text. BM25 outperforms dense vector-based retrieval methods in many [RAG benchmark tasks](https://hazyresearch.stanford.edu/blog/2024-05-20-m2-bert-retrieval).

User can use vector search extensions such as `pgvecto.rs` or `pgvector` for efficient searches in postgres.

Important

Based on our initial tests, HNSW indexing does not support the sparse vectors generated by BM25 very well. The high sparsity prevents effective navigation within the graph.

*   [Installation](http://github.com/tensorchord/pg_bestmatch.rs#installation)
*   [How does it work?](http://github.com/tensorchord/pg_bestmatch.rs#how-does-it-work)
*   [Usage](http://github.com/tensorchord/pg_bestmatch.rs#usage)
*   [Build from source](http://github.com/tensorchord/pg_bestmatch.rs#build-from-source)
*   [Comparison with pg\_search](http://github.com/tensorchord/pg_bestmatch.rs#comparison-with-pg_search)
*   [Reference](http://github.com/tensorchord/pg_bestmatch.rs#Reference)

Installation
------------

[](http://github.com/tensorchord/pg_bestmatch.rs#installation)

CREATE EXTENSION pg\_bestmatch;
SET search\_path TO public, bm\_catalog;

How does it work?
-----------------

[](http://github.com/tensorchord/pg_bestmatch.rs#how-does-it-work)

*   Create an BM25 statistics based on your document set by `bm25_create(table_name, column_name, statistic_name);`. It will create a materilized view to record the stats.
*   Generate document sparse vector by `bm25_document_to_svector(statistic_name, passage)`
*   For query, generate query sparse vector `bm25_query_to_svector(statistic_name, query)`
*   Calculate the score by dot product between the query sparse vector and the document sparse vector
*   Currently we use huggingface tokenizer with `bert-base-uncased` vocabulary set to tokenize words. Might support more configuration on tokenizer in the future.

Usage
-----

[](http://github.com/tensorchord/pg_bestmatch.rs#usage)

Here is an example workflow demonstrating the usage of this extension with the example of [Stanford LoCo benchmark](https://hazyresearch.stanford.edu/blog/2024-05-20-m2-bert-retrieval).

0.  Load the dataset. Here is a script for you if you want to experience `pg_bestmatch` with the dataset.

wget https://huggingface.co/api/datasets/hazyresearch/LoCoV1-Documents/parquet/default/test/0.parquet -O documents.parquet
wget https://huggingface.co/api/datasets/hazyresearch/LoCoV1-Queries/parquet/default/test/0.parquet -O queries.parquet

import pandas as pd
from sqlalchemy import create\_engine
import numpy as np
from psycopg2.extensions import register\_adapter, AsIs

def adapter\_numpy\_float64(numpy\_float64):
    return AsIs(numpy\_float64)

def adapter\_numpy\_int64(numpy\_int64):
    return AsIs(numpy\_int64)

def adapter\_numpy\_float32(numpy\_float32):
    return AsIs(numpy\_float32)

def adapter\_numpy\_int32(numpy\_int32):
    return AsIs(numpy\_int32)

def adapter\_numpy\_array(numpy\_array):
    return AsIs(tuple(numpy\_array))

register\_adapter(np.float64, adapter\_numpy\_float64)
register\_adapter(np.int64, adapter\_numpy\_int64)
register\_adapter(np.float32, adapter\_numpy\_float32)
register\_adapter(np.int32, adapter\_numpy\_int32)
register\_adapter(np.ndarray, adapter\_numpy\_array)

db\_url \= "postgresql://localhost:5432/pg\_bestmatch\_test"
engine \= create\_engine(db\_url)

def load\_documents():
    df \= pd.read\_parquet("documents.parquet")
    df.to\_sql("documents", engine, if\_exists\='replace', index\=False)

def load\_queries():
    df \= pd.read\_parquet("queries.parquet")
    df\['answer\_pids'\] \= df\['answer\_pids'\].apply(lambda x: str(x\[0\]))    
    df.to\_sql("queries", engine, if\_exists\='replace', index\=False)

load\_documents()
load\_queries()

1.  Create BM25 statistics for the `documents` table.

SELECT bm25\_create('documents', 'passage', 'documents\_passage\_bm25', 0.75, 1.2);

2.  Add an embedding column to the `documents` and `queries` tables and update the embeddings for documents and queries.

ALTER TABLE documents ADD COLUMN embedding svector; \-- for pgvecto.rs users
ALTER TABLE documents ADD COLUMN embedding sparsevec; \-- for pgvector users

UPDATE documents SET embedding \= bm25\_document\_to\_svector('documents\_passage\_bm25', passage)::svector; \-- for pgvecto.rs users
UPDATE documents SET embedding \= bm25\_document\_to\_svector('documents\_passage\_bm25', passage, 'pgvector')::sparsevec; \-- for pgvector users

3.  (Optional) Create a vector index on the sparse vector column.

CREATE INDEX ON documents USING vectors (embedding svector\_dot\_ops); \-- for pgvecto.rs users
CREATE INDEX ON documents USING ivfflat (embedding sparsevec\_ip\_ops); \-- for pgvector users

4.  Perform a vector search to find the most relevant documents for each query.

ALTER TABLE queries ADD COLUMN embedding svector; \-- for pgvecto.rs users
ALTER TABLE queries ADD COLUMN embedding sparsevec; \-- for pgvector users

UPDATE queries SET embedding \= bm25\_query\_to\_svector('documents\_passage\_bm25', query)::svector; \-- for pgvecto.rs users
UPDATE queries SET embedding \= bm25\_query\_to\_svector('documents\_passage\_bm25', query, 'pgvector')::sparsevec; \-- for pgvector users

SELECT sum((array\[answer\_pids\] \= array(SELECT pid FROM documents WHERE queries.dataset \= documents.dataset ORDER BY queries.embedding <#\> documents.embedding LIMIT 1))::int) FROM queries;

This workflow showcases how to leverage BM25 text queries and vector search in PostgreSQL using this extension. The Top 1 recall of BM25 on this dataset is `0.77`. If you reproduce the result, your operations are correct.

Build from source
-----------------

[](http://github.com/tensorchord/pg_bestmatch.rs#build-from-source)

Before building, you should have `PostgreSQL`, `Rust` and `Cargo` installed on your system.

1.  Install `cargo-pgrx`.

cargo install cargo-pgrx --version v0.12.0-alpha.1

2.  Initialize `cargo-pgrx`.

cargo pgrx init --pg16=$(which pg\_config)   # assuming that you have PostgreSQL 16 installed

3.  Build.

cargo pgrx install --release    # if you want to install it on your machine
cargo pgrx package  # if you want to package \`pg\_bestmatch\`

Comparison with pg\_search
--------------------------

[](http://github.com/tensorchord/pg_bestmatch.rs#comparison-with-pg_search)

*   `pg_bestmatch.rs` only provides methods for generating sparse vectors and does not support index-based search (which can be achieved by pgvecto.rs or pgvector).
*   `pg_search` performs BM25 retrieval via the external `tantivy` engine, which may have limitations when combined with transactions, filters, or JOIN operations. Since `pg_bestmatch.rs` is entirely native to Postgres, it offers full compatibility with these operations inside postgres.

Reference
---------

[](http://github.com/tensorchord/pg_bestmatch.rs#reference)

*   `tokenize`
    *   Description: Tokenizes an input string into individual tokens.
    *   Example:
        
        SELECT tokenize('i have an apple'); \-- result: {i,have,an,apple}
        
*   `bm25_create`
    *   Description: Creates BM25 statistics for a specified table and column.
    *   Usage:
        
        SELECT bm25\_create('documents', 'passage', 'documents\_passage\_bm25');
        
    *   Parameters:
        *   `table_name`: Name of the table.
        *   `column_name`: Name of the column.
        *   `stat_name`: Name of the BM25 statistics.
        *   `b`: BM25 parameter (default 0.75).
        *   `k`: BM25 parameter (default 1.2).
*   `bm25_refresh`
    *   Description: Updates the BM25 statistics to reflect any changes in the underlying data.
    *   Usage:
        
        SELECT bm25\_refresh('documents\_passage\_bm25');
        
    *   Parameters:
        *   `stat_name`: Name of the BM25 statistics to update.
*   `bm25_drop`
    *   Description: Deletes the BM25 statistics for a specified table and column.
    *   Usage:
        
        SELECT bm25\_drop('documents\_passage\_bm25');
        
    *   Parameters:
        *   `stat_name`: Name of the BM25 statistics to delete.
*   `bm25_document_to_svector`
    *   Description: Converts document text into a sparse vector representation.
    *   Usage:
        
        SELECT bm25\_document\_to\_svector('documents\_passage\_bm25', 'document\_text');
        
    *   Parameters:
        *   `stat_name`: Name of the BM25 statistics.
        *   `document_text`: The text of the document.
        *   `style`: Emits `pgvecto.rs`\-style sparse vector or `pgvector`\-style sparse vector.
*   `bm25_query_to_svector`
    *   Description: Converts query text into a sparse vector representation.
    *   Usage:
        
        SELECT bm25\_query\_to\_svector('documents\_passage\_bm25', 'We begin, as always, with the text.');
        
    *   Parameters:
        *   `stat_name`: Name of the BM25 statistics.
        *   `query_text`: The text of the query.
        *   `style`: Emits `pgvecto.rs`\-style sparse vector or `pgvector`\-style sparse vector.